<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Yao Wei</title>
<style>
	img.rounded-img {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
  
  h1,body {
    font-size : 15px;
    font-family: Lato, Helvetica, sans-serif;
  }
</style></head>

<body>

<table border="0" cellspacing="20">
  <tbody><tr>
    <td><img class="rounded-img" src="./img/YaoWei.jpg" style="height:220px"></td>
    <td width="30"></td>
    <td valign="top">
      <font size="6"><b>Yao</b> WEI</font><br>
      <img src="./img/name.png" style="height:57px"><br>
      <font size="3"> yao.wei@utwente.nl<br></font>
	    <br>
      <font size="2"> PhD Student at <a href="https://www.itc.nl/">ITC</a>, <a href="https://www.utwente.nl/">University of Twente</a><br></font>
	    <font size="2"> 7522NH Enschede, The Netherlands<br></font>
	<br>
      <font size="3"> [<a href="https://scholar.google.com/citations?user=NYYC2JwAAAAJ&hl=en/">GoogleScholar</a>] &nbsp; [<a href="https://www.researchgate.net/profile/Yao-Wei-11/">ResearchGate</a>] &nbsp; [<a href="https://www.linkedin.com/in/yao-wei-1062471ab/">LinkedIn</a>] &nbsp; [<a href="https://orcid.org/0000-0003-4672-4584">ORCID</a>]<br></font>
      <font size="3"> More details can be found through my <a href="./files/Resume_YW.pdf">resume</a><br></font>
    </td>
  </tr></tbody></table>

<font size="3"> 
</font><p style="width:1200px"><font size="3">I am a <a href="https://people.utwente.nl/yao.wei">PhD candidate</a> at Faculty of Geo-Information Science and Earth Observation (ITC), University of Twente, under the supervision of <a href="https://research.utwente.nl/en/persons/george-vosselman">Prof. George Vosselman</a>. Meanwhile, I am a member of Scene Understanding Group led by <a href="https://sites.google.com/site/michaelyingyang">Prof. Michael Ying Yang</a> at University of Bath. My research interests include machine learning, 3D scene understanding and deep generative models.
<br><br>
I received the M.S. degree in photogrammetry and remote sensing from <a href="http://en.whu.edu.cn/">Wuhan University</a> where I worked in road extraction from aerial and satellite images using deep learning techniques (<a href="./files/publications/Master_Thesis_Yao_Wei_2021.pdf">Master Thesis</a>), advised by <a href="http://gpcv.whu.edu.cn/">Prof. Shunping Ji</a>. Before that, I received the B.S. degree in geographic information science from <a href="http://english.upc.edu.cn/">China University of Petroleum</a>, Qingdao, China.
<br><br>
If you are interested in my research or have any use cases that you would like to collaborate on, feel free to contact me!
</a></font><a> 

<br>
<div><b>Latest work🔥:</b>
<div style="position: relative; left: 10px"><br>
	<table cellpadding="5">
	<tr>
      <td>
        <img src="./img/masterbedroom.gif" width="140">&nbsp;&nbsp;
      </td>
	  <td>
        <b>Yao Wei</b>, Martin Renqiang Min, George Vosselman, Li Erran Li, Michael Ying Yang<br>
        <u><a href="">Planner3D: LLM-enhanced Graph Prior Meets 3D Indoor Scene Explicit Regularization</a></u>
        <br>2024 Under Review <br>
		[<a href="https://weiyao1996.github.io/planner3d/">Homepage</a>] &nbsp; [<a href="https://arxiv.org/abs/2403.12848">Preprint</a>] &nbsp; Paper &nbsp; Code
      </td>
    </tr>
	</table>
</div>

<br>
</a></p><p><a><b>Selected publications:</b></a></p><div><a>
<div style="position: relative; left: 10px">
  <table cellpadding="5">

<tbody>
<!-- 	<tr>
      <td>
        <img src="./img/masterbedroom.gif" width="140">&nbsp;&nbsp;
      </td>
	  <td>
        <b>Yao Wei</b>, Martin Renqiang Min, George Vosselman, Li Erran Li, Michael Ying Yang<br>
        <u><a href="">Compositional 3D Scene Synthesis with Scene Graph Guided Layout-Shape Generation</a></u>
        <br>2024 ArXiv <br>
		[<a href="https://arxiv.org/abs/2403.12848">Preprint</a>] 
      </td>
    </tr> -->
	
	<tr>
      <td>
        <img src="./img/iccvw2023.png" class="rounded-img" style="width:140px">&nbsp;&nbsp; 
      </td>
	  <td>
        <b>Yao Wei</b>, George Vosselman, Michael Ying Yang<br>
        <u><a href="https://openaccess.thecvf.com/content/ICCV2023W/AI3DCC/html/Wei_BuilDiff_3D_Building_Shape_Generation_Using_Single-Image_Conditional_Point_Cloud_ICCVW_2023_paper.html">BuilDiff: 3D Building Shape Generation using Single-Image Conditional Point Cloud Diffusion Models</a></u>
        <br>2023 <i>IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)</i><br>
		[<a href="https://arxiv.org/abs/2309.00158">Preprint</a>] &nbsp; [<a href="./files/publications/ICCVW_2023.pdf">Paper</a>] &nbsp; [<a href="https://github.com/weiyao1996/BuilDiff">Code</a>] 
      </td>
    </tr>
	
	<tr>
      <td>
        <img src="./img/bmvc2022.png" class="rounded-img" style="width:140px">&nbsp;&nbsp; 
      </td>
	  <td>
        <b>Yao Wei</b>, George Vosselman, Michael Ying Yang<br>
        <u><a href="https://bmvc2022.mpi-inf.mpg.de/569/">Flow-based GAN for 3D Point Cloud Generation from a Single Image</a></u>
        <br>2022 <i>British Machine Vision Conference (BMVC)</i><br>
		[<a href="https://arxiv.org/abs/2210.04072">Preprint</a>] &nbsp; [<a href="./files/publications/BMVC_2022.pdf">Paper</a>] &nbsp; [<a href="https://github.com/weiyao1996/FlowGAN">Code</a>]
      </td>
    </tr>
	   
	<tr>
      <td>
        <img src="./img/tgrs2021.png" class="rounded-img" style="width:140px">&nbsp;&nbsp; 
      </td>
	  <td>
        <b>Yao Wei</b>, Shunping Ji<br>
        <u><a href="https://ieeexplore.ieee.org/document/9372390">Scribble-based Weakly Supervised Deep Learning for Road Surface Extraction from Remote Sensing Images</a></u>
        <br>2021 <i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i><br>
		[<a href="https://arxiv.org/abs/2010.13106">Preprint</a>] &nbsp; [<a href="./files/publications/TGRS_2021.pdf">Paper</a>] &nbsp; [<a href="https://github.com/weiyao1996/ScRoadExtractor">Code</a>]
		  <font color="orange"><br>🏆<b>ESI Highly Cited Paper (Top 1%)</b><br></font>
      </td>
    </tr>
	    
	<tr>
      <td>
        <img src="./img/tgrs2020.png" class="rounded-img" style="width:140px">&nbsp;&nbsp; 
      </td>
	  <td>
        <b>Yao Wei</b>, Kai Zhang, Shunping Ji<br>
        <u><a href="https://ieeexplore.ieee.org/document/9094008">Simultaneous Road Surface and Centerline Extraction From Large-Scale Remote Sensing Images Using CNN-Based Segmentation and Tracing</a></u>
        <br>2020 <i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i><br>
		[<a href="./files/publications/TGRS_2020.pdf">Paper</a>] &nbsp; [<a href="https://github.com/astro-ck/Road-Extraction">Code</a>]
      </td>
    </tr>

	</table>
	</div>

<br>
<div><b>Other publications:</b>
<div style="position: relative; left: 10px"><br>
	<table cellpadding="5">
	<tr>
      <td>
        <img src="./img/tgrs2022.png" class="rounded-img" style="width:140px">&nbsp;&nbsp; 
      </td>
	  <td>
        Jingjing Yan, Shunping Ji, <b>Yao Wei</b><br>
        <u><a href="https://ieeexplore.ieee.org/document/9714410">A Combination of Convolutional and Graph Neural Networks for Regularized Road Surface Extraction</a></u>
        <br>2022 <i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i><br>
      </td>
    </tr>
		<tr>
      <td>
        <img src="./img/igarss2019.png" class="rounded-img" style="width:140px">&nbsp;&nbsp; 
      </td>
	  <td>
        <b>Yao Wei</b>, Kai Zhang, Shunping Ji<br>
        <u><a href="https://ieeexplore.ieee.org/document/8898565">Road Network Extraction from Satellite Images Using CNN Based Segmentation and Tracing</a></u>
        <br>2019 <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</i><br>
		[<a href="./files/publications/IGARSS_2019.pdf">Paper</a>] &nbsp; [<a href="https://github.com/astro-ck/RoadTracer-M">Code</a>]
      </td>
    </tr>
	</table>
	一种基于卷积神经网络弱监督学习的遥感影像道路分割方法 <u><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=SCPD&dbname=SCPD2021&filename=CN112070779A&v=bcHFAMxmdDnall1C8c8XCRuWDeZY20myRQuADFVgoZmyhLPAxnku3dHJCLZj8je5">ZL202010771919.6</a></u> | 季顺平; <b>魏瑶</b> | 2020<br>
	一种同时提取遥感影像道路路面和中心线的深度学习方法 <u><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=SCPD&dbname=SCPD2020&filename=CN111046768A&v=xAQvwbi%25mmd2FIXRfrOYdUy6vENxaJTm5J%25mmd2F7%25mmd2BjfyRns7PCRrwi0oMc6QvwxOllym%25mmd2BpgMn">ZL201911228166.8</a></u> | 季顺平; <b>魏瑶</b>; 张凯 | 2019<br>
</div>
	
<br>
<div><b>Presentations:</b>
<div style="position: relative; left: 20px"><br>
	<a href="./files/publications/Poster_ICCVW_AI3DCC_18.pdf">Poster</a> | <a href="https://ai3dcc.github.io/">AI for 3D Content Creation (AI3DCC) </a>, <a href="https://iccv2023.thecvf.com/">International Conference on Computer Vision (ICCV) </a> | Paris, France | 2 October 2023<br>
	Poster | <a href="https://missing-data.compute.dtu.dk/">Summer School on Missing Data, Augmentation and Generative Models </a> | Copenhagen, Denmark | 14 August 2023<br>
	<a href="./files/publications/Poster_BMVC_0569.pdf">Poster</a> | <a href="https://bmvc2022.org/">British Machine Vision Conference (BMVC)</a> | London, UK | 22 November 2022<br>
	Oral | <a href="https://www.ncgeo.nl/index.php/nl/actueel/nieuws/item/2847-ncg-symposium-2022-programma">Netherlands Center for Geodesy and Geo-Informatics (NCG) Symposium</a> | Wageningen, Netherlands | 26 April 2022<br>
	<a href="./files/publications/Poster_IGARSS_WEI-0802.pdf">Poster</a> | <a href="https://igarss2019.org/">IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</a> | Yokohama, Japan | 2 August 2019<br>
</div>
		
<br>
<div><b>Academic activities:</b>
<div style="position: relative; left: 20px"><br>
	As a reviewer at <i>CVPR</i>, <i>ISPRS Journal of Photogrammetry and Remote Sensing</i>, <i>IEEE Sensors Journal</i>, <i>Geo-spatial Information Science</i>, <i>International Journal of Digital Earth</i>
</div>

<!-- <br>
<div><b>Awards:</b>
<div style="position: relative; left: 20px"><br>
	CSC fellowship
</div> -->

<br>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/4.js?i=5xnz617lbna&amp;m=1&amp;h=256&amp;c=ff0000&amp;r=0" async="async"></script>
